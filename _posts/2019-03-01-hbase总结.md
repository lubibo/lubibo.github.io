---
layout:     post   				    # 使用的布局（不需要改）
title:      hbas总结	     # 标题 
# subtitle:                            #副标题
date:       2019-03-01 				# 时间
author:     Lubibo 						# 作者
header-img:  	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 分布式数据库
    - hbase
    - hadoop
---
## <center>Hbase简要总结</center>
###1. 背景
- 关系数据库已经流行很多年，并且Hadoop已经有了HDFS和MapReduce，为什么需要HBase?
    - Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于Hadoop MapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时处理应用的需求.
    - HDFS面向批量访问模式，不是随机访问模式
    - 传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题（分库分表也不能很好解决）
- HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，是谷歌BigTable的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase的目标是处理非常庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表。
###2. 基础原理
- 数据逻辑模型
  - 表：HBase采用表来组织数据，表由行和列组成，列划分为若干个列族
  - 行(row)：每个HBase表都由若干行组成，每个行由行键（row key）来标识。
  - 列族(column family)：一个HBase表被分组成许多“列族”（Column Family）的集合，它是基本的访问控制单元。
  - 列限定符(column )：列族里的数据通过列限定符（或列）来定位。
  - 单元格(cell)：在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，总被视为字节数组byte[]。
  - 时间戳：每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引。
  - HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]。
    ![jpg](/img/hbase总结/hbase数据逻辑模型.jpg)
- 基础架构
  ![png](/img/hbase总结/hbase基础架构.png)
  - Clinet：包含访问HBase的接口，并维护cache来加快对HBase的访问。
  - Hmaster：管理HRegionServer，负责HRegionserver的负载均衡，管理和分配HRegion,实现DDL操作，管理namespace和table的元数据。
  - HRegionServer：存放和管理本地HRegion，读写HDFS，管理Table中的数据，Client直接通过HRegionServer读写数据。HRegionServer包含的组件：
    - WAL(Write Ahead Log)：WAL的存储格式，物理上是Hadoop的Sequence File。
    - BlockCache：读缓存
    - MemStore：写缓存,当其中一个列族的Memstore达到阈值flush时，所有其他列族的也会flush,每次Memstore Flush，会为每个列族都创建一个新的StoreFile,每个列族同时刷新的目的是为了一个region的数据存储在一个服务器节点上。当StoreFile文件数量增长到一定阈值,会触发compact操作,将多个StoreFile合并成一个StoreFile。 
    - Hfiles将行存储在磁盘上，是storeFile的具体实现。
  - HRegion：HBase通过RowKey将表水平切割成多个HRegion，一个HRegion有一个startKey和endKey的row key。每个Regions被分配到HBase的某个节点上，该节点被称为RegionServer，这些RegionServer负责数据的读取和写入。**HRegion的定位：**
    ![jpg](/img/hbase总结/hbase三层结构.jpg)
    ![jpg](/img/hbase总结/三层结构详解.jpg)
    - 一般来说，root表只能有一个region，meta表可以有多个region。
    - 客户端首先是访问zookeeper，获得root表相关信息，然后访问root表进而获得meta表的位置信息；然后再读取meta表的信息，进而获得用户表的存储位置，然后再到响应的region server读取用户表数据。
  - Zookeeper：保证任何时候，集群中只有一个master。Master与RegionServers 启动时会向ZooKeeper注册，存贮所有Region的寻址入口，实时监控Regionserver的上线和下线信息，并实时通知给Master存放整个HBase集群的元数据，以及集群的状态信息。
- 物理模型
  - Table中的所有行都按照row key的字典序排列。
  - Region是按照大小分割的，每个表开始只有一个region，随着数据增多，region不断增大，当增大到一个阀值的时候，region就会等分为两个新的region，之后会有越来越多的region。
  - Region是HBase中分布式存储和负载均衡的最小单元。不同Region分布到不同RegionServer上。
  - Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，**每个store保存一个columns family**；
  - 每个Strore又由一个memStore和0至多个StoreFile组成；memStore存储在内存中,StoreFile存储在HDFS上。
  - storeFile在HDFS上的具体实现是Hfile文件，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile。Hfile的具体实现如下，
  ![jpg](/img/hbase总结/hfile结构.jpg)
    - Data：数据块，保存表中的数据（可被压缩）
    - Meta（Optioal）：元数据块，保存用户自定义的 kv 对（可被压缩）
    - FileInfo：HFile的元数据信息，用户也可以在这一部分添加自己的元信息。
    - Data Index：存储Data块索引信息的块文件，每条索引的key 是被索引的 block 的第一条记录的 key。
    - Meta Index：存储Meta块索引信息的块文件
    - Trailer：它存储了FileInfo、DataIndex、MetaIndex块的偏移值和寻址信息。
###3. 写流程
  - Client写入 --> 存入MemStore，一直到MemStore满 --> Flush成一个StoreFile，直至增长到一定阈值 --> 触发Compact合并操作 --> 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 --> 当StoreFiles Compact后，逐步形成越来越大的StoreFile --> 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上。
###4. HBase与传统的关系数据库的区别
- 数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式，HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串。
- 数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等，因为HBase在设计上就避免了复杂的表和表之间的关系。
- 存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的。
- 数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来。
- 数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留。
- 可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的，能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩。

###5. Hbase的java API操作例子
- 创建表
```java
    Configuration conf = HBaseConfiguration.create();
    Connection connection = ConnectionFactory.createConnection(conf);  
    Admin admin = connection.getAdmin(); 
    String tableName = "test";
    String colFamily = "info";
    TableName tName = TableName.valueOf(tableName);  
    HTableDescriptor hTableDesc = new HTableDescriptor(tName);  
    HColumnDescriptor hColumnDesc = new HColumnDescriptor(col);  
    hTableDesc.addFamily(hColumnDesc);  
    admin.createTable(hTableDesc);
    admin.close();
    connection.close();
```
- 插入数据
```java
    Configuration conf = HBaseConfiguration.create();
    Connection connection = ConnectionFactory.createConnection(conf);  
    String tablename = "test";
    String colFamily = "info";
    String col = "name";
    String rowKey = "1";
    String value = "ljs";
    Table table = connection.getTable(TableName.valueOf(tablename));  
    Put put = new Put(Bytes.toBytes(rowKey)); put.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col), Bytes.toBytes(value));  
    table.put(put); 
    table.close();    
    connection.close();
```
- 读取一条数据
```java
Table table = connection.getTable(TableName.valueOf(tableName));  
Get get = new Get(Bytes.toBytes(rowKey));  
get.addFamily(Bytes.toBytes(colFamily)); 
get.addColumn(Bytes.toBytes(colFamily), Bytes.toBytes(col));  
Result result = table.get(get);  
Cell[] cells = result.rawCells();  
for (Cell cell : cells) {  
   System.out.println("RowName: " + new String(CellUtil.cloneRow(cell)) + " ");  
  System.out.println("Timetamp: " + cell.getTimestamp() + " ");  
   System.out.println("column Family: " + new 
   String(CellUtil.cloneFamily(cell)) + " ");  
   System.out.println("row Name: " + new String(CellUtil.cloneQualifier(cell))  
   + " ");  
   System.out.println("value: " + new String(CellUtil.cloneValue(cell)) + " ");  
} 
```
- 全表扫描
```java
Connection connection = ConnectionFactory.createConnection(conf);  
Table table = connection.getTable(TableName.valueOf("test"));
ResultScanner results = table.getScanner(new Scan()); 
for (Result result : results) {  
    for (Cell cell : result.rawCells()) {  
        System.out.println(  
                "行键:" + new String(CellUtil.cloneRow(cell)) + "\t" +  
                "列族:" + new String(CellUtil.cloneFamily(cell)) + "\t" +   
                "列名:" + new String(CellUtil.cloneQualifier(cell)) + "\t" +   
                "值:" + new String(CellUtil.cloneValue(cell)));  
    }  
}  
results.close();    
table.close();  
connection.close();

```